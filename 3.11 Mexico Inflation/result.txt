X shape: torch.Size([1, 28, 1])
y shape: torch.Size([1, 1])
Epoch [100/3000], Loss: 0.000000
Epoch [200/3000], Loss: 0.000000
Epoch [300/3000], Loss: 0.000000
Epoch [400/3000], Loss: 0.000000
Epoch [500/3000], Loss: 0.000000
Epoch [600/3000], Loss: 0.000000
Epoch [700/3000], Loss: 0.000000
Epoch [800/3000], Loss: 0.000000
Epoch [900/3000], Loss: 0.000000
Epoch [1000/3000], Loss: 0.000000
Epoch [1100/3000], Loss: 0.000000
Epoch [1200/3000], Loss: 0.000000
Epoch [1300/3000], Loss: 0.000000
Epoch [1400/3000], Loss: 0.000000
Epoch [1500/3000], Loss: 0.000000
Epoch [1600/3000], Loss: 0.000000
Epoch [1700/3000], Loss: 0.000000
Epoch [1800/3000], Loss: 0.000000
Epoch [1900/3000], Loss: 0.000000
Epoch [2000/3000], Loss: 0.000000
Epoch [2100/3000], Loss: 0.000000
Epoch [2200/3000], Loss: 0.000000
Epoch [2300/3000], Loss: 0.000000
Epoch [2400/3000], Loss: 0.000000
Epoch [2500/3000], Loss: 0.000000
Epoch [2600/3000], Loss: 0.000000
Epoch [2700/3000], Loss: 0.000000
Epoch [2800/3000], Loss: 0.000000
Epoch [2900/3000], Loss: 0.000000
Epoch [3000/3000], Loss: 0.000000

Predicted next day price: 4.65
PS C:\GitHub\DeepLearning> & C:/Anaconda3/envs/DeepLearning/python.exe "c:/GitHub/DeepLearning/3.11 Mexico Inflation/3.11.py"
X shape: torch.Size([1, 28, 1])
y shape: torch.Size([1, 1])
Epoch [100/3000], Loss: 0.000000009475433
Epoch [200/3000], Loss: 0.000000000001119
Epoch [300/3000], Loss: 0.000000000000000
Epoch [400/3000], Loss: 0.000000000000000
Epoch [500/3000], Loss: 0.000000000000000
Epoch [600/3000], Loss: 0.000000000000000
Epoch [700/3000], Loss: 0.000000000000000
Epoch [800/3000], Loss: 0.000000000000000
Epoch [900/3000], Loss: 0.000000000000000
Epoch [1000/3000], Loss: 0.000000000000000
Epoch [1100/3000], Loss: 0.000000000000000
Epoch [1200/3000], Loss: 0.000000000000000
Epoch [1300/3000], Loss: 0.000000000000000
Epoch [1400/3000], Loss: 0.000000000000000
Epoch [1500/3000], Loss: 0.000000000000000
Epoch [1600/3000], Loss: 0.000000000000000
Epoch [1700/3000], Loss: 0.000000000000000
Epoch [1800/3000], Loss: 0.000000000000000
Epoch [1900/3000], Loss: 0.000000000000000
Epoch [2000/3000], Loss: 0.000000000000000
Epoch [2100/3000], Loss: 0.000000000000000
Epoch [2200/3000], Loss: 0.000000000000000
Epoch [2300/3000], Loss: 0.000000000000000
Epoch [2400/3000], Loss: 0.000000000000000
Epoch [2500/3000], Loss: 0.000000000000000
Epoch [2600/3000], Loss: 0.000000000000000
Epoch [2700/3000], Loss: 0.000000000000000
Epoch [2800/3000], Loss: 0.000000000000000
Epoch [2900/3000], Loss: 0.000000000000000
Epoch [3000/3000], Loss: 0.000000000000000

Predicted next day price: 4.65
PS C:\GitHub\DeepLearning> & C:/Anaconda3/envs/DeepLearning/python.exe "c:/GitHub/DeepLearning/3.11 Mexico Inflation/3.11.py"
X shape: torch.Size([25, 4, 1])
y shape: torch.Size([25, 1])
Epoch [100/3000], Loss: 0.004397393640829
Epoch [200/3000], Loss: 0.002338741494896
Epoch [300/3000], Loss: 0.001875298214145
Epoch [400/3000], Loss: 0.001747090445406
Epoch [500/3000], Loss: 0.002795681211865
Epoch [600/3000], Loss: 0.001752318697982
Epoch [700/3000], Loss: 0.002479856251739
Epoch [800/3000], Loss: 0.002000364969717
Epoch [900/3000], Loss: 0.003382354509085
Epoch [1000/3000], Loss: 0.003120089764707
Epoch [1100/3000], Loss: 0.001712223311188
Epoch [1200/3000], Loss: 0.001722570610582
Epoch [1300/3000], Loss: 0.001668618686381
Epoch [1400/3000], Loss: 0.001609441416804
Epoch [1500/3000], Loss: 0.002690511639230
Epoch [1600/3000], Loss: 0.001593705455889
Epoch [1700/3000], Loss: 0.001475320204463
Epoch [1800/3000], Loss: 0.001471587331253
Epoch [1900/3000], Loss: 0.002800135640427
Epoch [2000/3000], Loss: 0.001607721700566
Epoch [2100/3000], Loss: 0.002350141425268
Epoch [2200/3000], Loss: 0.001825525177992
Epoch [2300/3000], Loss: 0.001582238852279
Epoch [2400/3000], Loss: 0.002957804070320
Epoch [2500/3000], Loss: 0.001434401417782
Epoch [2600/3000], Loss: 0.003024163539521
Epoch [2700/3000], Loss: 0.001499377416621
Epoch [2800/3000], Loss: 0.002586403192254
Epoch [2900/3000], Loss: 0.002559668733738
Epoch [3000/3000], Loss: 0.002819384520990

Predicted next day price: 3.53